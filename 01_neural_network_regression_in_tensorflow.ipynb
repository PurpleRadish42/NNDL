{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0553834d",
   "metadata": {},
   "source": [
    "# Introduction to regression with neural networks in tensorflow\n",
    "\n",
    "We're going to predict a number using regression with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd159a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fa94f",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f146547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e643c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20b771",
   "metadata": {},
   "source": [
    "### Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26817a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c679c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-7.0), np.float64(3.0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cbfa41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our NumPy arrays into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1d39223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c995cf7",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. Creating a model - define input and output layers, as well as the hidden layers\n",
    "2. Compiling a model - define the loss function and optimiser\n",
    "3. Fitting a model - leting a model try to find patterns between X & y (features and labels).\n",
    "\n",
    "<img src=\"./steps-in-modelling.png\">\n",
    "\n",
    "<img src=\"./modeling.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "621c92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 8.6755 - mae: 8.6755\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.5430 - mae: 8.5430\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.4105 - mae: 8.4105\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.2780 - mae: 8.2780\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.1455 - mae: 8.1455\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.0130 - mae: 8.0130\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.8805 - mae: 7.8805\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.7480 - mae: 7.7480\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.6155 - mae: 7.6155\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.4830 - mae: 7.4830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x718ed01790a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Fix the data shape - both X and y need to by 2D\n",
    "X = tf.expand_dims(X,axis=1) #Shape: (8,1)\n",
    "y = tf.expand_dims(y,axis=1) #Shape: (8,1)\n",
    "\n",
    "#1. Create a model using sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "#3. Fit the model\n",
    "model.fit(X, y, epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d03c6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.483496]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tf.constant([17.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af298f1b",
   "metadata": {},
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d7899a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 11.4638 - mae: 11.4638\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11.3313 - mae: 11.3313\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11.0663 - mae: 11.0663\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10.9338 - mae: 10.9338\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 10.8013 - mae: 10.8013\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10.6688 - mae: 10.6688\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10.5363 - mae: 10.5363\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.4038 - mae: 10.4038\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.2713 - mae: 10.2713\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10.1388 - mae: 10.1388\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.0063 - mae: 10.0063\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.8738 - mae: 9.8738\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.7413 - mae: 9.7413\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.6088 - mae: 9.6088\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.3438 - mae: 9.3438\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.2113 - mae: 9.2113\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.0788 - mae: 9.0788\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.9463 - mae: 8.9463\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.8138 - mae: 8.8138\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.6813 - mae: 8.6813\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.5488 - mae: 8.5488\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.4163 - mae: 8.4163\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.2838 - mae: 8.2838\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.1513 - mae: 8.1513\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.0188 - mae: 8.0188\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.8863 - mae: 7.8863\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.7538 - mae: 7.7538\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.6213 - mae: 7.6213\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4888 - mae: 7.4888\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.3563 - mae: 7.3563\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.2600 - mae: 7.2600\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2544 - mae: 7.2544\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2487 - mae: 7.2487\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2431 - mae: 7.2431\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.2375 - mae: 7.2375\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2319 - mae: 7.2319\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2263 - mae: 7.2263\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2206 - mae: 7.2206\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2150 - mae: 7.2150\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2094 - mae: 7.2094\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.2038 - mae: 7.2038\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1981 - mae: 7.1981\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.1925 - mae: 7.1925\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.1869 - mae: 7.1869\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1812 - mae: 7.1812\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1756 - mae: 7.1756\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1700 - mae: 7.1700\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.1644 - mae: 7.1644\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 7.1588 - mae: 7.1588\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1531 - mae: 7.1531\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.1475 - mae: 7.1475\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.1419 - mae: 7.1419\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.1363 - mae: 7.1363\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.1306 - mae: 7.1306\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1250 - mae: 7.1250\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1194 - mae: 7.1194\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1138 - mae: 7.1138\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1081 - mae: 7.1081\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.1025 - mae: 7.1025\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0969 - mae: 7.0969\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0913 - mae: 7.0913\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.0856 - mae: 7.0856\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.0800 - mae: 7.0800\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0744 - mae: 7.0744\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0687 - mae: 7.0687\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0631 - mae: 7.0631\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.0575 - mae: 7.0575\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0519 - mae: 7.0519\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0463 - mae: 7.0463\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.0406 - mae: 7.0406\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.0350 - mae: 7.0350\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0294 - mae: 7.0294\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.0238 - mae: 7.0238\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.0181 - mae: 7.0181\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.0125 - mae: 7.0125\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.0069 - mae: 7.0069\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0012 - mae: 7.0012\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9956 - mae: 6.9956\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.9900 - mae: 6.9900\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9844 - mae: 6.9844\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9788 - mae: 6.9788\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.9731 - mae: 6.9731\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9675 - mae: 6.9675\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.9619 - mae: 6.9619\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.9563 - mae: 6.9563\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.9506 - mae: 6.9506\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.9450 - mae: 6.9450\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9394 - mae: 6.9394\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9338 - mae: 6.9338\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9281 - mae: 6.9281\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.9225 - mae: 6.9225\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9169 - mae: 6.9169\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9113 - mae: 6.9113\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9056 - mae: 6.9056\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9000 - mae: 6.9000\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8944 - mae: 6.8944\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.8888 - mae: 6.8888\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.8831 - mae: 6.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x718e403ac410>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild the model\n",
    "#1. create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),  # Fixed: \"optimzer\" -> \"optimizer\"\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model (we'll train this time longer)\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb0096c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       " array([[-7.],\n",
       "        [-4.],\n",
       "        [-1.],\n",
       "        [ 2.],\n",
       "        [ 5.],\n",
       "        [ 8.],\n",
       "        [11.],\n",
       "        [14.]])>,\n",
       " <tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
       " array([[ 3.],\n",
       "        [ 6.],\n",
       "        [ 9.],\n",
       "        [12.],\n",
       "        [15.],\n",
       "        [18.],\n",
       "        [21.],\n",
       "        [24.]])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the data again\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb94488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.760126]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if prediction has improved\n",
    "model.predict(tf.constant([17.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a202c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - loss: 14.4073 - mae: 14.4073\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 13.9187 - mae: 13.9187\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 13.4405 - mae: 13.4405\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 12.9639 - mae: 12.9639\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 12.4860 - mae: 12.4860\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12.0064 - mae: 12.0064\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11.5139 - mae: 11.5139\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 11.0035 - mae: 11.0035\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.4747 - mae: 10.4747\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.9274 - mae: 9.9274\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.3499 - mae: 9.3499\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.7378 - mae: 8.7378\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.0886 - mae: 8.0886\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.3950 - mae: 7.3950\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.6490 - mae: 6.6490\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.8455 - mae: 5.8455\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0299 - mae: 5.0299\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.1667 - mae: 4.1667\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.0745 - mae: 4.0745\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9799 - mae: 3.9799\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8827 - mae: 3.8827\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9513 - mae: 3.9513\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.8846 - mae: 3.8846\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.9306 - mae: 3.9306\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8925 - mae: 3.8925\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.9123 - mae: 3.9123\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.9060 - mae: 3.9060\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8871 - mae: 3.8871\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.9131 - mae: 3.9131\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8618 - mae: 3.8618\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9204 - mae: 3.9204\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.8541 - mae: 3.8541\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.9092 - mae: 3.9092\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.8674 - mae: 3.8674\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.8907 - mae: 3.8907\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8760 - mae: 3.8760\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8652 - mae: 3.8652\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8833 - mae: 3.8833\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8396 - mae: 3.8396\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8909 - mae: 3.8909\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8250 - mae: 3.8250\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8906 - mae: 3.8906\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8398 - mae: 3.8398\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8675 - mae: 3.8675\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8473 - mae: 3.8473\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8418 - mae: 3.8418\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8549 - mae: 3.8549\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8159 - mae: 3.8159\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8626 - mae: 3.8626\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7988 - mae: 3.7988\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8690 - mae: 3.8690\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8120 - mae: 3.8120\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8431 - mae: 3.8431\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.8197 - mae: 3.8197\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8171 - mae: 3.8171\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8275 - mae: 3.8275\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7910 - mae: 3.7910\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.8355 - mae: 3.8355\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7764 - mae: 3.7764\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8436 - mae: 3.8436\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7853 - mae: 3.7853\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8174 - mae: 3.8174\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7932 - mae: 3.7932\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7911 - mae: 3.7911\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8013 - mae: 3.8013\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7648 - mae: 3.7648\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8128 - mae: 3.8128\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7517 - mae: 3.7517\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8169 - mae: 3.8169\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7597 - mae: 3.7597\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7904 - mae: 3.7904\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7678 - mae: 3.7678\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7639 - mae: 3.7639\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7761 - mae: 3.7761\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.7383 - mae: 3.7383\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7916 - mae: 3.7916\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7269 - mae: 3.7269\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7889 - mae: 3.7889\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7351 - mae: 3.7351\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7621 - mae: 3.7621\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7435 - mae: 3.7435\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7353 - mae: 3.7353\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7520 - mae: 3.7520\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7134 - mae: 3.7134\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7677 - mae: 3.7677\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7032 - mae: 3.7032\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7596 - mae: 3.7596\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7116 - mae: 3.7116\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7325 - mae: 3.7325\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7202 - mae: 3.7202\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7053 - mae: 3.7053\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7308 - mae: 3.7308\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.6845 - mae: 3.6845\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.7447 - mae: 3.7447\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.6804 - mae: 3.6804\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7290 - mae: 3.7290\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.6890 - mae: 3.6890\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7016 - mae: 3.7016\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.6978 - mae: 3.6978\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.6741 - mae: 3.6741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x718eea17ca70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try to improve the model (with extra hidden layer - 100 hidden units)\n",
    "\n",
    "# 1. Create the model\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=\"mae\",\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02488c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x718e40194040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.72446]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to predict\n",
    "model.predict(tf.constant([17.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
