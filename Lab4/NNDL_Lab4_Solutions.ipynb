{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acd8490",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning - Lab 4\n",
    "\n",
    "This notebook solves both problems mentioned in **Lab #4** using TensorFlow and NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Program #1: House Price Prediction (Regression)\n",
    "\n",
    "We'll create a synthetic version of the `Houseprice_Bangalore` dataset and use a neural network to predict house prices. We'll train using:\n",
    "\n",
    "- Batch Gradient Descent\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "- Mini-Batch Gradient Descent\n",
    "\n",
    "Metric: Mean Squared Error (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dataset\n",
    "np.random.seed(0)\n",
    "num_samples = 1000\n",
    "\n",
    "# Features: bedrooms, size (sqft), age, bathrooms\n",
    "X = np.random.randint(1, 6, size=(num_samples, 4)).astype(float)\n",
    "X[:, 1] *= 500  # size in sqft\n",
    "X[:, 2] *= 5    # age in years\n",
    "\n",
    "# Price formula (just for simulation)\n",
    "y = 50000 + (X[:, 0] * 100000) + (X[:, 1] * 300) - (X[:, 2] * 1000) + (X[:, 3] * 50000)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    'Batch Gradient Descent': tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    'Stochastic Gradient Descent': tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    'Mini-Batch Gradient Descent': tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "}\n",
    "\n",
    "batch_sizes = {\n",
    "    'Batch Gradient Descent': len(X_train),\n",
    "    'Stochastic Gradient Descent': 1,\n",
    "    'Mini-Batch Gradient Descent': 32\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name in optimizers:\n",
    "    print(f\"Training with {name}\")\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=optimizers[name], loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=batch_sizes[name], verbose=0)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    results[name] = mse\n",
    "    print(f\"{name} - Test MSE: {mse:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3327a34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Program #2: Single-Layer NN Alarm System (Manual Backpropagation)\n",
    "\n",
    "We will manually implement a single-layer neural network with 2 inputs (`x₁`, `x₂`) and one output using sigmoid activation. We'll perform:\n",
    "\n",
    "- Forward pass\n",
    "- Backward pass (backpropagation using delta rule)\n",
    "- Update weights & bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and expected outputs (truth table)\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([[0], [1], [1], [1]])  # Alarm triggers if any sensor is on\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_deriv(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Initialize weights and bias\n",
    "np.random.seed(1)\n",
    "weights = np.random.rand(2,1)\n",
    "bias = np.random.rand(1)\n",
    "lr = 0.1\n",
    "\n",
    "# Forward pass\n",
    "z = np.dot(X, weights) + bias\n",
    "y_pred = sigmoid(z)\n",
    "\n",
    "# MSE before update\n",
    "error = y - y_pred\n",
    "mse_before = np.mean(error**2)\n",
    "\n",
    "# Backpropagation\n",
    "d_pred = error * sigmoid_deriv(y_pred)\n",
    "weights_update = lr * np.dot(X.T, d_pred)\n",
    "bias_update = lr * np.sum(d_pred)\n",
    "\n",
    "# Update\n",
    "weights += weights_update\n",
    "bias += bias_update\n",
    "\n",
    "# Final weights and bias\n",
    "print(\"MSE before update:\", round(mse_before, 4))\n",
    "print(\"Updated Weights:\\n\", weights)\n",
    "print(\"Updated Bias:\\n\", bias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
